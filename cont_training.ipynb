{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from custom_agent.CTCE.sac_agent import Agent\n",
    "from custom_agent.CTCE.citylearn_wrapper import CityLearnWrapper\n",
    "\n",
    "from citylearn.wrappers import NormalizedSpaceWrapper, StableBaselines3Wrapper\n",
    "from custom_reward.custom_reward import CustomReward\n",
    "\n",
    "from stable_baselines3 import SAC\n",
    "\n",
    "from citylearn.citylearn import CityLearnEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeEnv(schema_path, reward_function):\n",
    "    # create environment\n",
    "    env = CityLearnEnv(schema = schema_path, reward_function = reward_function, central_agent=True)\n",
    "    \n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_path = \"data/schema.json\"\n",
    "\n",
    "env = makeEnv(schema_path, CustomReward)\n",
    "env = NormalizedSpaceWrapper(env)\n",
    "env = CityLearnWrapper(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hkolstee/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "/home/hkolstee/.local/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n",
      "/home/hkolstee/.local/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "sac_agent = Agent(env, batch_size=256, buffer_max_size=1000000, log_dir = \"tensorboard_logs/new_cont\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_dir = \"models\"\n",
    "step = \"1700000\"\n",
    "\n",
    "sac_agent.actor.load(os.path.join(weights_dir, \"actor_\" + step))\n",
    "sac_agent.critic1.load(os.path.join(weights_dir, \"critic1_\" + step))\n",
    "sac_agent.critic2.load(os.path.join(weights_dir, \"critic2_\" + step))\n",
    "sac_agent.critic1_targ.load(os.path.join(weights_dir, \"critic1_targ_\" + step))\n",
    "sac_agent.critic2_targ.load(os.path.join(weights_dir, \"critic2_targ_\" + step))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# make agent\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# training run\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     \u001b[43msac_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2500000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearn_delay\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearn_freq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearn_weight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/masterThesis/masterThesis/custom_agent/CTCE/sac_agent.py:287\u001b[0m, in \u001b[0;36mAgent.train\u001b[0;34m(self, nr_steps, max_episode_len, warmup_steps, learn_delay, learn_freq, learn_weight, checkpoint)\u001b[0m\n\u001b[1;32m    284\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_action(obs)\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# transition\u001b[39;00m\n\u001b[0;32m--> 287\u001b[0m next_obs, reward, done, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m# step increment \u001b[39;00m\n\u001b[1;32m    290\u001b[0m ep_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/masterThesis/masterThesis/custom_agent/CTCE/citylearn_wrapper.py:31\u001b[0m, in \u001b[0;36mCityLearnWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m     27\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m    Citylearn expects a list of actions, even when using a central agent.\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m    Also, does not provide truncation information\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     next_obs, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43maction\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     truncated \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m next_obs[\u001b[38;5;241m0\u001b[39m], reward[\u001b[38;5;241m0\u001b[39m], done, truncated, info\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gym/core.py:289\u001b[0m, in \u001b[0;36mWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gym/core.py:349\u001b[0m, in \u001b[0;36mActionWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gym/core.py:323\u001b[0m, in \u001b[0;36mObservationWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m--> 323\u001b[0m     observation, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation(observation), reward, done, info\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/citylearn/citylearn.py:806\u001b[0m, in \u001b[0;36mCityLearnEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    803\u001b[0m actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_actions(actions)\n\u001b[1;32m    805\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m building, building_actions \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuildings, actions):\n\u001b[0;32m--> 806\u001b[0m     \u001b[43mbuilding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_actions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbuilding_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_variables()\n\u001b[1;32m    810\u001b[0m \u001b[38;5;66;03m# NOTE:\u001b[39;00m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;66;03m# This call to retrieve each building's observation dictionary is an expensive call especially since the observations \u001b[39;00m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;66;03m# are retrieved again to send to agent but the observations in dict form is needed for the reward function to easily\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;66;03m# extract building-level values. Can't think of a better way to handle this without giving the reward direct access to\u001b[39;00m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;66;03m# env, which is not the best design for competition integrity sake. Will revisit the building.observations() function\u001b[39;00m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;66;03m# to see how it can be optimized.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/citylearn/building.py:1830\u001b[0m, in \u001b[0;36mDynamicsBuilding.apply_actions\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1828\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1829\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mapply_actions(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1830\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_dynamics_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1832\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimulate_dynamics:\n\u001b[1;32m   1833\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_indoor_dry_bulb_temperature()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/citylearn/building.py:1979\u001b[0m, in \u001b[0;36mLSTMDynamicsBuilding._update_dynamics_input\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1972\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Updates and returns the input time series for the dynmaics prediction model.\u001b[39;00m\n\u001b[1;32m   1973\u001b[0m \n\u001b[1;32m   1974\u001b[0m \u001b[38;5;124;03mUpdates the model input with the input variables for the current time step. \u001b[39;00m\n\u001b[1;32m   1975\u001b[0m \u001b[38;5;124;03mThe variables in the input will have length of lookback + 1.\u001b[39;00m\n\u001b[1;32m   1976\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1978\u001b[0m \u001b[38;5;66;03m# get relevant observations for the current time step\u001b[39;00m\n\u001b[0;32m-> 1979\u001b[0m observations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservations\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude_all\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperiodic_normalization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1981\u001b[0m \u001b[38;5;66;03m# append current time step observations to model input\u001b[39;00m\n\u001b[1;32m   1982\u001b[0m \u001b[38;5;66;03m# leave out the oldest set of observations and keep only the previous n\u001b[39;00m\n\u001b[1;32m   1983\u001b[0m \u001b[38;5;66;03m# where n is the lookback + 1 (to include current time step observations)\u001b[39;00m\n\u001b[1;32m   1984\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdynamics\u001b[38;5;241m.\u001b[39m_model_input \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1985\u001b[0m     l[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdynamics\u001b[38;5;241m.\u001b[39mlookback:] \u001b[38;5;241m+\u001b[39m [(observations[k] \u001b[38;5;241m-\u001b[39m min_)\u001b[38;5;241m/\u001b[39m(max_ \u001b[38;5;241m-\u001b[39m min_)] \n\u001b[1;32m   1986\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m l, k, min_, max_ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1991\u001b[0m     )\n\u001b[1;32m   1992\u001b[0m ]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/citylearn/building.py:734\u001b[0m, in \u001b[0;36mBuilding.observations\u001b[0;34m(self, include_all, normalize, periodic_normalization)\u001b[0m\n\u001b[1;32m    728\u001b[0m include_all \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m include_all \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m include_all\n\u001b[1;32m    730\u001b[0m observations \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    731\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\n\u001b[1;32m    733\u001b[0m         k\u001b[38;5;241m.\u001b[39mlstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menergy_simulation\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(k\u001b[38;5;241m.\u001b[39mlstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m))[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_step] \n\u001b[0;32m--> 734\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menergy_simulation\u001b[49m)\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, np\u001b[38;5;241m.\u001b[39mndarray)\n\u001b[1;32m    735\u001b[0m     },\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\n\u001b[1;32m    737\u001b[0m         k\u001b[38;5;241m.\u001b[39mlstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweather\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(k\u001b[38;5;241m.\u001b[39mlstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m))[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_step] \n\u001b[1;32m    738\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweather)\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, np\u001b[38;5;241m.\u001b[39mndarray)\n\u001b[1;32m    739\u001b[0m     },\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\n\u001b[1;32m    741\u001b[0m         k\u001b[38;5;241m.\u001b[39mlstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpricing\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(k\u001b[38;5;241m.\u001b[39mlstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m))[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_step] \n\u001b[1;32m    742\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpricing)\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, np\u001b[38;5;241m.\u001b[39mndarray)\n\u001b[1;32m    743\u001b[0m     },\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\n\u001b[1;32m    745\u001b[0m         k\u001b[38;5;241m.\u001b[39mlstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcarbon_intensity\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(k\u001b[38;5;241m.\u001b[39mlstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m))[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_step] \n\u001b[1;32m    746\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcarbon_intensity)\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, np\u001b[38;5;241m.\u001b[39mndarray)\n\u001b[1;32m    747\u001b[0m     },\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msolar_generation\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28mabs\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolar_generation[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_step]),\n\u001b[1;32m    749\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\n\u001b[1;32m    750\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcooling_storage_soc\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcooling_storage\u001b[38;5;241m.\u001b[39msoc[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_step],\n\u001b[1;32m    751\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheating_storage_soc\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheating_storage\u001b[38;5;241m.\u001b[39msoc[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_step],\n\u001b[1;32m    752\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdhw_storage_soc\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdhw_storage\u001b[38;5;241m.\u001b[39msoc[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_step],\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124melectrical_storage_soc\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39melectrical_storage\u001b[38;5;241m.\u001b[39msoc[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_step],\n\u001b[1;32m    754\u001b[0m     },\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcooling_demand\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__energy_from_cooling_device[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_step] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mabs\u001b[39m(\u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcooling_storage\u001b[38;5;241m.\u001b[39menergy_balance[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_step], \u001b[38;5;241m0.0\u001b[39m)),\n\u001b[1;32m    756\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheating_demand\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__energy_from_heating_device[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_step] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mabs\u001b[39m(\u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheating_storage\u001b[38;5;241m.\u001b[39menergy_balance[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_step], \u001b[38;5;241m0.0\u001b[39m)),\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdhw_demand\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__energy_from_dhw_device[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_step] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mabs\u001b[39m(\u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdhw_storage\u001b[38;5;241m.\u001b[39menergy_balance[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_step], \u001b[38;5;241m0.0\u001b[39m)),\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnet_electricity_consumption\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet_electricity_consumption[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_step],\n\u001b[1;32m    759\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcooling_electricity_consumption\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcooling_electricity_consumption[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_step],\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheating_electricity_consumption\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheating_electricity_consumption[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_step],\n\u001b[1;32m    761\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdhw_electricity_consumption\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdhw_electricity_consumption[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_step],\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcooling_storage_electricity_consumption\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcooling_storage_electricity_consumption[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_step],\n\u001b[1;32m    763\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheating_storage_electricity_consumption\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheating_storage_electricity_consumption[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_step],\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdhw_storage_electricity_consumption\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdhw_storage_electricity_consumption[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_step],\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124melectrical_storage_electricity_consumption\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39melectrical_storage_electricity_consumption[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_step],\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcooling_device_cop\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcooling_device\u001b[38;5;241m.\u001b[39mget_cop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweather\u001b[38;5;241m.\u001b[39moutdoor_dry_bulb_temperature[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_step], heating\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m    767\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheating_device_cop\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheating_device\u001b[38;5;241m.\u001b[39mget_cop(\n\u001b[1;32m    768\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweather\u001b[38;5;241m.\u001b[39moutdoor_dry_bulb_temperature[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_step], heating\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    769\u001b[0m             ) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheating_device, HeatPump) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheating_device\u001b[38;5;241m.\u001b[39mefficiency,\n\u001b[1;32m    770\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindoor_dry_bulb_temperature_set_point\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menergy_simulation\u001b[38;5;241m.\u001b[39mindoor_dry_bulb_temperature_set_point[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_step],\n\u001b[1;32m    771\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindoor_dry_bulb_temperature_delta\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mabs\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menergy_simulation\u001b[38;5;241m.\u001b[39mindoor_dry_bulb_temperature[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_step] \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menergy_simulation\u001b[38;5;241m.\u001b[39mindoor_dry_bulb_temperature_set_point[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_step]),\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moccupant_count\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menergy_simulation\u001b[38;5;241m.\u001b[39moccupant_count[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_step],\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpower_outage\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__power_outage_signal[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_step],\n\u001b[1;32m    774\u001b[0m }\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_all:\n\u001b[1;32m    777\u001b[0m     valid_observations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(data\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/citylearn/building.py:105\u001b[0m, in \u001b[0;36mBuilding.energy_simulation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimate_observation_space(include_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimate_action_space()\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21menergy_simulation\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m EnergySimulation:\n\u001b[1;32m    107\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Temporal features, cooling, heating, dhw and plug loads, solar generation and indoor environment time series.\"\"\"\u001b[39;00m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__energy_simulation\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    # make agent\n",
    "    \n",
    "    # training run\n",
    "    sac_agent.train(2500000, warmup_steps=10000, learn_delay = 10000, learn_freq = 1, learn_weight = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
