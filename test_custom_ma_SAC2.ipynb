{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST of custom Multi-Agent SAC agent on citylearn env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-11 14:42:16.266925: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from citylearn.citylearn import CityLearnEnv\n",
    "from citylearn.wrappers import NormalizedSpaceWrapper, StableBaselines3Wrapper\n",
    "\n",
    "from custom_agent.CTDE.ma_sac_agents_2 import Agents\n",
    "\n",
    "from custom_reward.custom_reward import CustomReward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrapperEnv:\n",
    "    \"\"\"\n",
    "    Env to wrap provide Citylearn Env data without providing full env\n",
    "    Preventing attribute access outside of the available functions\n",
    "    \"\"\"\n",
    "    def __init__(self, env_data):\n",
    "        self.observation_names = env_data['observation_names']\n",
    "        self.action_names = env_data['action_names']\n",
    "        self.observation_space = env_data['observation_space']\n",
    "        self.action_space = env_data['action_space']\n",
    "        self.time_steps = env_data['time_steps']\n",
    "        self.seconds_per_time_step = env_data['seconds_per_time_step']\n",
    "        self.random_seed = env_data['random_seed']\n",
    "        self.buildings_metadata = env_data['buildings_metadata']\n",
    "        self.episode_tracker = env_data['episode_tracker']\n",
    "    \n",
    "    def get_metadata(self):\n",
    "        return {'buildings': self.buildings_metadata}\n",
    "    \n",
    "def makeEnv(schema_path, reward_function):\n",
    "    # create environment\n",
    "    env = CityLearnEnv(schema = schema_path, reward_function = reward_function, central_agent=False)\n",
    "\n",
    "    env_data = dict(\n",
    "        observation_names = env.observation_names,\n",
    "        action_names = env.action_names,\n",
    "        observation_space = env.observation_space,\n",
    "        action_space = env.action_space,\n",
    "        time_steps = env.time_steps,\n",
    "        random_seed = None,\n",
    "        episode_tracker = None,\n",
    "        seconds_per_time_step = None,\n",
    "        buildings_metadata = env.get_metadata()['buildings']\n",
    "    )\n",
    "\n",
    "    wrapper_env = WrapperEnv(env_data)\n",
    "    return env, wrapper_env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'month': False,\n",
       " 'day_type': True,\n",
       " 'hour': True,\n",
       " 'daylight_savings_status': False,\n",
       " 'outdoor_dry_bulb_temperature': True,\n",
       " 'outdoor_dry_bulb_temperature_predicted_6h': True,\n",
       " 'outdoor_dry_bulb_temperature_predicted_12h': True,\n",
       " 'outdoor_dry_bulb_temperature_predicted_24h': True,\n",
       " 'outdoor_relative_humidity': False,\n",
       " 'outdoor_relative_humidity_predicted_6h': False,\n",
       " 'outdoor_relative_humidity_predicted_12h': False,\n",
       " 'outdoor_relative_humidity_predicted_24h': False,\n",
       " 'diffuse_solar_irradiance': True,\n",
       " 'diffuse_solar_irradiance_predicted_6h': True,\n",
       " 'diffuse_solar_irradiance_predicted_12h': True,\n",
       " 'diffuse_solar_irradiance_predicted_24h': True,\n",
       " 'direct_solar_irradiance': True,\n",
       " 'direct_solar_irradiance_predicted_6h': True,\n",
       " 'direct_solar_irradiance_predicted_12h': True,\n",
       " 'direct_solar_irradiance_predicted_24h': True,\n",
       " 'carbon_intensity': True,\n",
       " 'indoor_dry_bulb_temperature': True,\n",
       " 'average_unmet_cooling_setpoint_difference': False,\n",
       " 'indoor_relative_humidity': False,\n",
       " 'non_shiftable_load': True,\n",
       " 'solar_generation': True,\n",
       " 'cooling_storage_soc': False,\n",
       " 'heating_storage_soc': False,\n",
       " 'dhw_storage_soc': True,\n",
       " 'electrical_storage_soc': True,\n",
       " 'net_electricity_consumption': True,\n",
       " 'electricity_pricing': True,\n",
       " 'electricity_pricing_predicted_6h': True,\n",
       " 'electricity_pricing_predicted_12h': True,\n",
       " 'electricity_pricing_predicted_24h': True,\n",
       " 'cooling_device_cop': False,\n",
       " 'heating_device_cop': False,\n",
       " 'cooling_demand': True,\n",
       " 'heating_demand': False,\n",
       " 'dhw_demand': True,\n",
       " 'cooling_electricity_consumption': False,\n",
       " 'heating_electricity_consumption': False,\n",
       " 'dhw_electricity_consumption': False,\n",
       " 'occupant_count': True,\n",
       " 'indoor_dry_bulb_temperature_set_point': True,\n",
       " 'indoor_dry_bulb_temperature_delta': False,\n",
       " 'power_outage': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "schema_path = \"data/schema.json\"\n",
    "\n",
    "env, wrapper_env = makeEnv(schema_path, CustomReward)\n",
    "\n",
    "display(env.buildings[0].observation_metadata)\n",
    "\n",
    "# wrap environment for a more workable env\n",
    "env = NormalizedSpaceWrapper(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hkolstee/.local/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n",
      "/home/hkolstee/.local/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "sac_agent = Agents(env, batch_size=100, buffer_max_size=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Box([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       "  1. 1. 1. 1. 1. 1. 1. 1.], (32,), float32),\n",
       " Box([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       "  1. 1. 1. 1. 1. 1. 1. 1.], (32,), float32),\n",
       " Box([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       "  1. 1. 1. 1. 1. 1. 1. 1.], (32,), float32)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3960000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Episode 151 total reward: [-424.83581396 -375.96816404 -350.4731386 ]] ~ :   3%|â–Ž         | 108817/3960000 [4:02:12<142:51:53,  7.49it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m sac_agent \u001b[38;5;241m=\u001b[39m Agents(env, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, buffer_max_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100000\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# training run\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[43msac_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnr_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5500\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m720\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearn_delay\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearn_freq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearn_weight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# save training logs for this run\u001b[39;00m\n\u001b[1;32m     12\u001b[0m logs_list\u001b[38;5;241m.\u001b[39mappend(logs)\n",
      "File \u001b[0;32m~/masterThesis/custom_agent/CTDE/ma_sac_agents_2.py:394\u001b[0m, in \u001b[0;36mAgents.train\u001b[0;34m(self, nr_steps, max_episode_len, warmup_steps, learn_delay, learn_freq, learn_weight)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m>\u001b[39m learn_delay \u001b[38;5;129;01mand\u001b[39;00m step \u001b[38;5;241m%\u001b[39m learn_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(learn_weight):\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;66;03m# learning step\u001b[39;00m\n\u001b[0;32m--> 394\u001b[0m         status, loss_actor, loss_critic, policy_entropy, alpha, loss_alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m         \u001b[38;5;66;03m# if buffer full enough for a batch\u001b[39;00m\n\u001b[1;32m    397\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m status:\n\u001b[1;32m    398\u001b[0m             \u001b[38;5;66;03m# keep track for logs\u001b[39;00m\n",
      "File \u001b[0;32m~/masterThesis/custom_agent/CTDE/ma_sac_agents_2.py:246\u001b[0m, in \u001b[0;36mAgents.learn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    243\u001b[0m loss_critic \u001b[38;5;241m=\u001b[39m loss_critic1 \u001b[38;5;241m+\u001b[39m loss_critic2\n\u001b[1;32m    245\u001b[0m \u001b[38;5;66;03m# backward prop\u001b[39;00m\n\u001b[0;32m--> 246\u001b[0m \u001b[43mloss_critic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;66;03m# step down gradient\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritics1[agent_idx]\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:433\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_tensor_str\u001b[38;5;241m.\u001b[39m_str(\u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents)\n\u001b[0;32m--> 433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, inputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    435\u001b[0m ):\n\u001b[1;32m    436\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the gradient of current tensor wrt graph leaves.\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \n\u001b[1;32m    438\u001b[0m \u001b[38;5;124;03m    The graph is differentiated using the chain rule. If the tensor is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;124;03m            used to compute the attr::tensors.\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "logs_list = []\n",
    "warmup_steps = 5000\n",
    "\n",
    "for i in range(3):\n",
    "    # make agent\n",
    "    sac_agent = Agents(env, batch_size=100, buffer_max_size=100000)\n",
    "    \n",
    "    # training run\n",
    "    logs = sac_agent.train(nr_steps = 5500 * 720, warmup_steps = warmup_steps, learn_delay = 100, learn_freq = 1, learn_weight = 1)\n",
    "    \n",
    "    # save training logs for this run\n",
    "    logs_list.append(logs)\n",
    "\n",
    "# print(logs_list.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
