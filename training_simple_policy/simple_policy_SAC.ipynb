{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training of a simple policy using the custom reward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../venv/\")\n",
    "!source ../venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.21.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "gym.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from citylearn.citylearn import CityLearnEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from citylearn.wrappers import NormalizedObservationWrapper, StableBaselines3Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.logger import TensorBoardOutputFormat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../custom_reward\")\n",
    "from custom_reward import CustomReward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function and a wrapper class as given in the local evaluation script provided by the challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrapperEnv:\n",
    "    \"\"\"\n",
    "    Env to wrap provide Citylearn Env data without providing full env\n",
    "    Preventing attribute access outside of the available functions\n",
    "    \"\"\"\n",
    "    def __init__(self, env_data):\n",
    "        self.observation_names = env_data['observation_names']\n",
    "        self.action_names = env_data['action_names']\n",
    "        self.observation_space = env_data['observation_space']\n",
    "        self.action_space = env_data['action_space']\n",
    "        self.time_steps = env_data['time_steps']\n",
    "        self.seconds_per_time_step = env_data['seconds_per_time_step']\n",
    "        self.random_seed = env_data['random_seed']\n",
    "        self.buildings_metadata = env_data['buildings_metadata']\n",
    "        self.episode_tracker = env_data['episode_tracker']\n",
    "    \n",
    "    def get_metadata(self):\n",
    "        return {'buildings': self.buildings_metadata}\n",
    "\n",
    "def create_citylearn_env(schema_path, reward_function, central_agent):\n",
    "    env = CityLearnEnv(schema=schema_path, reward_function=reward_function, central_agent=central_agent)\n",
    "\n",
    "    env_data = dict(\n",
    "        observation_names = env.observation_names,\n",
    "        action_names = env.action_names,\n",
    "        observation_space = env.observation_space,\n",
    "        action_space = env.action_space,\n",
    "        time_steps = env.time_steps,\n",
    "        random_seed = None,\n",
    "        episode_tracker = None,\n",
    "        seconds_per_time_step = None,\n",
    "        buildings_metadata = env.get_metadata()['buildings']\n",
    "    )\n",
    "\n",
    "    wrapper_env = WrapperEnv(env_data)\n",
    "    return env, wrapper_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_path = os.path.join(\"../data/\", \"schema.json\")\n",
    "\n",
    "env, wrapper_env = create_citylearn_env(schema_path, CustomReward, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.get_metadata()\n",
    "# env.reward_function.env_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare for SB3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = NormalizedObservationWrapper(env)\n",
    "env = StableBaselines3Wrapper(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create SAC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hkolstee/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "/home/hkolstee/.local/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n",
      "/home/hkolstee/.local/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = SAC(\"MlpPolicy\", env, tensorboard_log=\"./tensorboard_logs/\")\n",
    "\n",
    "# model = SAC.load(\"models/custom_reward_SAC6.zip\")\n",
    "model.set_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create custom callback to track reward values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Custom callback for plotting additional reward values in tensorboard\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose = 0):\n",
    "        super().__init__(verbose)\n",
    "\n",
    "    def _on_rollout_end(self) -> None:\n",
    "        self.logger.record(\"Comfort\", -self.training_env.get_attr(\"reward_function\")[0].comfort[0])\n",
    "        self.logger.record(\"Emissions\", -self.training_env.get_attr(\"reward_function\")[0].emissions[0])\n",
    "        self.logger.record(\"Grid\", -self.training_env.get_attr(\"reward_function\")[0].grid[0])\n",
    "        self.logger.record(\"Resilience\", -self.training_env.get_attr(\"reward_function\")[0].resilience[0])\n",
    "        self.logger.record(\"unmet hours of thermal comfort (u)\", -self.training_env.get_attr(\"reward_function\")[0].u[0])\n",
    "        self.logger.record(\"carbon emissions (g)\", -self.training_env.get_attr(\"reward_function\")[0].g[0])\n",
    "        self.logger.record(\"ramping (r)\", -self.training_env.get_attr(\"reward_function\")[0].r[0])\n",
    "        self.logger.record(\"daily peak (d)\", -self.training_env.get_attr(\"reward_function\")[0].d[0])\n",
    "        self.logger.record(\"load factor (l)\", -self.training_env.get_attr(\"reward_function\")[0].l[0])\n",
    "        self.logger.record(\"all-time peak (a)\", -self.training_env.get_attr(\"reward_function\")[0].a[0])\n",
    "        self.logger.record(\"thermal resilience (m)\", -self.training_env.get_attr(\"reward_function\")[0].m[0])\n",
    "        self.logger.record(\"normalized unserved energy (s)\", -self.training_env.get_attr(\"reward_function\")[0].s[0])\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.learn(total_timesteps = env.get_metadata()[\"simulation_time_steps\"] * 20, \n",
    "#             log_interval = 1)\n",
    "model.learn(total_timesteps = env.get_metadata()[\"simulation_time_steps\"] * 35, \n",
    "            log_interval = 1,\n",
    "            callback = CustomCallback())\n",
    "# model.save(\"models/custom_reward_SAC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>Building_1</th>\n",
       "      <th>Building_2</th>\n",
       "      <th>Building_3</th>\n",
       "      <th>District</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>annual_normalized_unserved_energy_total</th>\n",
       "      <td>0.015050</td>\n",
       "      <td>0.015185</td>\n",
       "      <td>0.014282</td>\n",
       "      <td>0.014839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annual_peak_average</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.059272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carbon_emissions_total</th>\n",
       "      <td>1.629445</td>\n",
       "      <td>1.565772</td>\n",
       "      <td>1.478256</td>\n",
       "      <td>1.557824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost_total</th>\n",
       "      <td>1.571454</td>\n",
       "      <td>1.515609</td>\n",
       "      <td>1.445369</td>\n",
       "      <td>1.510811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daily_one_minus_load_factor_average</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daily_peak_average</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.165031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discomfort_delta_average</th>\n",
       "      <td>-7.653084</td>\n",
       "      <td>-2.596345</td>\n",
       "      <td>-2.546652</td>\n",
       "      <td>-4.265360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discomfort_delta_maximum</th>\n",
       "      <td>2.608950</td>\n",
       "      <td>5.045345</td>\n",
       "      <td>3.502832</td>\n",
       "      <td>3.719042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discomfort_delta_minimum</th>\n",
       "      <td>-12.061934</td>\n",
       "      <td>-8.127138</td>\n",
       "      <td>-5.366928</td>\n",
       "      <td>-8.518667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discomfort_proportion</th>\n",
       "      <td>0.970547</td>\n",
       "      <td>0.729478</td>\n",
       "      <td>0.745424</td>\n",
       "      <td>0.815150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discomfort_too_cold_proportion</th>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.707090</td>\n",
       "      <td>0.742097</td>\n",
       "      <td>0.805643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discomfort_too_hot_proportion</th>\n",
       "      <td>0.002805</td>\n",
       "      <td>0.022388</td>\n",
       "      <td>0.003328</td>\n",
       "      <td>0.009507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electricity_consumption_total</th>\n",
       "      <td>1.639776</td>\n",
       "      <td>1.593253</td>\n",
       "      <td>1.500730</td>\n",
       "      <td>1.577920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthly_one_minus_load_factor_average</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.889900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one_minus_thermal_resilience_proportion</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.546032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power_outage_normalized_unserved_energy_total</th>\n",
       "      <td>0.776274</td>\n",
       "      <td>0.782561</td>\n",
       "      <td>0.709139</td>\n",
       "      <td>0.755991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ramping_average</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.882855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero_net_energy</th>\n",
       "      <td>1.683358</td>\n",
       "      <td>1.607706</td>\n",
       "      <td>1.510026</td>\n",
       "      <td>1.600364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "name                                           Building_1  Building_2  \\\n",
       "cost_function                                                           \n",
       "annual_normalized_unserved_energy_total          0.015050    0.015185   \n",
       "annual_peak_average                                   NaN         NaN   \n",
       "carbon_emissions_total                           1.629445    1.565772   \n",
       "cost_total                                       1.571454    1.515609   \n",
       "daily_one_minus_load_factor_average                   NaN         NaN   \n",
       "daily_peak_average                                    NaN         NaN   \n",
       "discomfort_delta_average                        -7.653084   -2.596345   \n",
       "discomfort_delta_maximum                         2.608950    5.045345   \n",
       "discomfort_delta_minimum                       -12.061934   -8.127138   \n",
       "discomfort_proportion                            0.970547    0.729478   \n",
       "discomfort_too_cold_proportion                   0.967742    0.707090   \n",
       "discomfort_too_hot_proportion                    0.002805    0.022388   \n",
       "electricity_consumption_total                    1.639776    1.593253   \n",
       "monthly_one_minus_load_factor_average                 NaN         NaN   \n",
       "one_minus_thermal_resilience_proportion          0.800000    0.571429   \n",
       "power_outage_normalized_unserved_energy_total    0.776274    0.782561   \n",
       "ramping_average                                       NaN         NaN   \n",
       "zero_net_energy                                  1.683358    1.607706   \n",
       "\n",
       "name                                           Building_3  District  \n",
       "cost_function                                                        \n",
       "annual_normalized_unserved_energy_total          0.014282  0.014839  \n",
       "annual_peak_average                                   NaN  1.059272  \n",
       "carbon_emissions_total                           1.478256  1.557824  \n",
       "cost_total                                       1.445369  1.510811  \n",
       "daily_one_minus_load_factor_average                   NaN  0.739478  \n",
       "daily_peak_average                                    NaN  1.165031  \n",
       "discomfort_delta_average                        -2.546652 -4.265360  \n",
       "discomfort_delta_maximum                         3.502832  3.719042  \n",
       "discomfort_delta_minimum                        -5.366928 -8.518667  \n",
       "discomfort_proportion                            0.745424  0.815150  \n",
       "discomfort_too_cold_proportion                   0.742097  0.805643  \n",
       "discomfort_too_hot_proportion                    0.003328  0.009507  \n",
       "electricity_consumption_total                    1.500730  1.577920  \n",
       "monthly_one_minus_load_factor_average                 NaN  0.889900  \n",
       "one_minus_thermal_resilience_proportion          0.266667  0.546032  \n",
       "power_outage_normalized_unserved_energy_total    0.709139  0.755991  \n",
       "ramping_average                                       NaN  0.882855  \n",
       "zero_net_energy                                  1.510026  1.600364  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "observations = env.reset()\n",
    "\n",
    "while not env.done:\n",
    "    actions, _ = model.predict(observations, deterministic=True)\n",
    "    observations, _, _, _ = env.step(actions)\n",
    "\n",
    "kpis = env.evaluate()\n",
    "kpis = kpis.pivot(index='cost_function', columns='name', values='value')\n",
    "kpis = kpis.dropna(how='all')\n",
    "display(kpis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
