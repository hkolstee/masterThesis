{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST of custom Multi-Agent SAC agent on citylearn env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-17 14:50:13.933730: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from citylearn.citylearn import CityLearnEnv\n",
    "from citylearn.wrappers import NormalizedSpaceWrapper, StableBaselines3Wrapper\n",
    "\n",
    "from custom_agent.CTDE.ma_sac_agents_shared_critic import Agents\n",
    "\n",
    "from custom_reward.custom_reward import CustomReward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrapperEnv:\n",
    "    \"\"\"\n",
    "    Env to wrap provide Citylearn Env data without providing full env\n",
    "    Preventing attribute access outside of the available functions\n",
    "    \"\"\"\n",
    "    def __init__(self, env_data):\n",
    "        self.observation_names = env_data['observation_names']\n",
    "        self.action_names = env_data['action_names']\n",
    "        self.observation_space = env_data['observation_space']\n",
    "        self.action_space = env_data['action_space']\n",
    "        self.time_steps = env_data['time_steps']\n",
    "        self.seconds_per_time_step = env_data['seconds_per_time_step']\n",
    "        self.random_seed = env_data['random_seed']\n",
    "        self.buildings_metadata = env_data['buildings_metadata']\n",
    "        self.episode_tracker = env_data['episode_tracker']\n",
    "    \n",
    "    def get_metadata(self):\n",
    "        return {'buildings': self.buildings_metadata}\n",
    "    \n",
    "def makeEnv(schema_path, reward_function):\n",
    "    # create environment\n",
    "    env = CityLearnEnv(schema = schema_path, reward_function = reward_function, central_agent=False)\n",
    "\n",
    "    env_data = dict(\n",
    "        observation_names = env.observation_names,\n",
    "        action_names = env.action_names,\n",
    "        observation_space = env.observation_space,\n",
    "        action_space = env.action_space,\n",
    "        time_steps = env.time_steps,\n",
    "        random_seed = None,\n",
    "        episode_tracker = None,\n",
    "        seconds_per_time_step = None,\n",
    "        buildings_metadata = env.get_metadata()['buildings']\n",
    "    )\n",
    "\n",
    "    wrapper_env = WrapperEnv(env_data)\n",
    "    return env, wrapper_env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'month': False,\n",
       " 'day_type': True,\n",
       " 'hour': True,\n",
       " 'daylight_savings_status': False,\n",
       " 'outdoor_dry_bulb_temperature': True,\n",
       " 'outdoor_dry_bulb_temperature_predicted_6h': True,\n",
       " 'outdoor_dry_bulb_temperature_predicted_12h': True,\n",
       " 'outdoor_dry_bulb_temperature_predicted_24h': True,\n",
       " 'outdoor_relative_humidity': False,\n",
       " 'outdoor_relative_humidity_predicted_6h': False,\n",
       " 'outdoor_relative_humidity_predicted_12h': False,\n",
       " 'outdoor_relative_humidity_predicted_24h': False,\n",
       " 'diffuse_solar_irradiance': True,\n",
       " 'diffuse_solar_irradiance_predicted_6h': True,\n",
       " 'diffuse_solar_irradiance_predicted_12h': True,\n",
       " 'diffuse_solar_irradiance_predicted_24h': True,\n",
       " 'direct_solar_irradiance': True,\n",
       " 'direct_solar_irradiance_predicted_6h': True,\n",
       " 'direct_solar_irradiance_predicted_12h': True,\n",
       " 'direct_solar_irradiance_predicted_24h': True,\n",
       " 'carbon_intensity': True,\n",
       " 'indoor_dry_bulb_temperature': True,\n",
       " 'average_unmet_cooling_setpoint_difference': False,\n",
       " 'indoor_relative_humidity': False,\n",
       " 'non_shiftable_load': True,\n",
       " 'solar_generation': True,\n",
       " 'cooling_storage_soc': False,\n",
       " 'heating_storage_soc': False,\n",
       " 'dhw_storage_soc': True,\n",
       " 'electrical_storage_soc': True,\n",
       " 'net_electricity_consumption': True,\n",
       " 'electricity_pricing': True,\n",
       " 'electricity_pricing_predicted_6h': True,\n",
       " 'electricity_pricing_predicted_12h': True,\n",
       " 'electricity_pricing_predicted_24h': True,\n",
       " 'cooling_device_cop': False,\n",
       " 'heating_device_cop': False,\n",
       " 'cooling_demand': True,\n",
       " 'heating_demand': False,\n",
       " 'dhw_demand': True,\n",
       " 'cooling_electricity_consumption': False,\n",
       " 'heating_electricity_consumption': False,\n",
       " 'dhw_electricity_consumption': False,\n",
       " 'occupant_count': True,\n",
       " 'indoor_dry_bulb_temperature_set_point': True,\n",
       " 'indoor_dry_bulb_temperature_delta': False,\n",
       " 'power_outage': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "schema_path = \"data/schema.json\"\n",
    "\n",
    "env, wrapper_env = makeEnv(schema_path, CustomReward)\n",
    "\n",
    "display(env.buildings[0].observation_metadata)\n",
    "\n",
    "# wrap environment for a more workable env\n",
    "env = NormalizedSpaceWrapper(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hkolstee/.local/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n",
      "/home/hkolstee/.local/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "sac_agent = Agents(env, batch_size=100, buffer_max_size=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Box([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       "  1. 1. 1. 1. 1. 1. 1. 1.], (32,), float32),\n",
       " Box([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       "  1. 1. 1. 1. 1. 1. 1. 1.], (32,), float32),\n",
       " Box([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       "  1. 1. 1. 1. 1. 1. 1. 1.], (32,), float32)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 180/3960000 [00:17<108:38:42, 10.12it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m sac_agent \u001b[38;5;241m=\u001b[39m Agents(env, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, buffer_max_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100000\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# training run\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[43msac_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnr_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5500\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m720\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearn_delay\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearn_freq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearn_weight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# save training logs for this run\u001b[39;00m\n\u001b[1;32m     12\u001b[0m logs_list\u001b[38;5;241m.\u001b[39mappend(logs)\n",
      "File \u001b[0;32m~/masterThesis/custom_agent/CTDE/ma_sac_agents_shared_critic.py:386\u001b[0m, in \u001b[0;36mAgents.train\u001b[0;34m(self, nr_steps, max_episode_len, warmup_steps, learn_delay, learn_freq, learn_weight, checkpoint)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m>\u001b[39m learn_delay \u001b[38;5;129;01mand\u001b[39;00m step \u001b[38;5;241m%\u001b[39m learn_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(learn_weight):\n\u001b[1;32m    385\u001b[0m         \u001b[38;5;66;03m# learning step\u001b[39;00m\n\u001b[0;32m--> 386\u001b[0m         status, loss_actor, loss_critic, policy_entropy, alpha, loss_alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m         \u001b[38;5;66;03m# if buffer full enough for a batch\u001b[39;00m\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m status:\n\u001b[1;32m    390\u001b[0m             \u001b[38;5;66;03m# keep track for logs\u001b[39;00m\n",
      "File \u001b[0;32m~/masterThesis/custom_agent/CTDE/ma_sac_agents_shared_critic.py:176\u001b[0m, in \u001b[0;36mAgents.learn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    172\u001b[0m     actor\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()    \n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# with grad \u001b[39;00m\n\u001b[1;32m    175\u001b[0m policy_act_prev_obs, log_prob_prev_obs \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[actor\u001b[38;5;241m.\u001b[39mnormal_distr_sample(obs) \u001b[38;5;28;01mfor\u001b[39;00m (actor, obs) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactors, observations)])\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# create entire set, without grad\u001b[39;00m\n\u001b[1;32m    178\u001b[0m policy_act_prev_obs_nograd \u001b[38;5;241m=\u001b[39m [act\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;28;01mfor\u001b[39;00m act \u001b[38;5;129;01min\u001b[39;00m policy_act_prev_obs]\n",
      "File \u001b[0;32m~/masterThesis/custom_agent/CTDE/ma_sac_agents_shared_critic.py:176\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    172\u001b[0m     actor\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()    \n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# with grad \u001b[39;00m\n\u001b[1;32m    175\u001b[0m policy_act_prev_obs, log_prob_prev_obs \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[\u001b[43mactor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormal_distr_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m (actor, obs) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactors, observations)])\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# create entire set, without grad\u001b[39;00m\n\u001b[1;32m    178\u001b[0m policy_act_prev_obs_nograd \u001b[38;5;241m=\u001b[39m [act\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;28;01mfor\u001b[39;00m act \u001b[38;5;129;01min\u001b[39;00m policy_act_prev_obs]\n",
      "File \u001b[0;32m~/masterThesis/custom_agent/SAC_components/actor.py:86\u001b[0m, in \u001b[0;36mActor.normal_distr_sample\u001b[0;34m(self, obs, reparameterize, deterministic)\u001b[0m\n\u001b[1;32m     83\u001b[0m log_prob \u001b[38;5;241m=\u001b[39m prob_distr\u001b[38;5;241m.\u001b[39mlog_prob(sample)\u001b[38;5;241m.\u001b[39msum(axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# correct change in prob density due to tanh \u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m#   (function = magic, taken from openAI spinning up)\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m log_prob \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m-\u001b[39m sample \u001b[38;5;241m-\u001b[39m functional\u001b[38;5;241m.\u001b[39msoftplus(\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m)))\u001b[38;5;241m.\u001b[39msum(axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# final action\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m#   constrain action within [-1, 1] with tanh,\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m#   unscale for regular action range.\u001b[39;00m\n\u001b[1;32m     91\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_action(torch\u001b[38;5;241m.\u001b[39mtanh(sample))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/fx/traceback.py:68\u001b[0m, in \u001b[0;36mformat_stack\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [current_meta\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack_trace\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# fallback to traceback.format_stack()\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m traceback\u001b[38;5;241m.\u001b[39mformat_list(\u001b[43mtraceback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m/usr/lib/python3.10/traceback.py:227\u001b[0m, in \u001b[0;36mextract_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[0;32m--> 227\u001b[0m stack \u001b[38;5;241m=\u001b[39m \u001b[43mStackSummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwalk_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m stack\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stack\n",
      "File \u001b[0;32m/usr/lib/python3.10/traceback.py:369\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[0;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[1;32m    366\u001b[0m filename \u001b[38;5;241m=\u001b[39m co\u001b[38;5;241m.\u001b[39mco_filename\n\u001b[1;32m    367\u001b[0m name \u001b[38;5;241m=\u001b[39m co\u001b[38;5;241m.\u001b[39mco_name\n\u001b[0;32m--> 369\u001b[0m \u001b[43mfnames\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m linecache\u001b[38;5;241m.\u001b[39mlazycache(filename, f\u001b[38;5;241m.\u001b[39mf_globals)\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# Must defer line lookups until we have called checkcache.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "logs_list = []\n",
    "warmup_steps = 5000\n",
    "\n",
    "for i in range(3):\n",
    "    # make agent\n",
    "    sac_agent = Agents(env, batch_size=100, buffer_max_size=100000)\n",
    "    \n",
    "    # training run\n",
    "    logs = sac_agent.train(nr_steps = 5500 * 720, warmup_steps = warmup_steps, learn_delay = 100, learn_freq = 1, learn_weight = 1)\n",
    "    \n",
    "    # save training logs for this run\n",
    "    logs_list.append(logs)\n",
    "\n",
    "# print(logs_list.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
